{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation over Sample Size on SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timeit\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA,MNIST,SVHN\n",
    "import torchvision.datasets as dset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from AE import *\n",
    "from Sampling import *\n",
    "from Metric import *\n",
    "from RealNVP import *\n",
    "import warnings\n",
    "import timeit\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "robjects.numpy2ri.activate()\n",
    "base = importr('base')\n",
    "rvinecop = importr('rvinecopulib')\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "trans_SVHN =transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = %pwd\n",
    "dataset_train = SVHN(path,split=\"train\", transform=trans_SVHN, download=False)\n",
    "dataset_test = SVHN(path,split=\"test\", transform=trans_SVHN, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model\n",
    "model_AE = ae_SVHN(image_size=32, hidden_dim=20, z_size=20, device='cpu')\n",
    "model_VAE = vae_SVHN(image_size=32, hidden_dim=20, z_size=20, device='cpu')\n",
    "model_AE.load_state_dict(torch.load('./ae_SVHN_200.pth', map_location=torch.device('cpu')))\n",
    "model_VAE.load_state_dict(torch.load('./vae_SVHN_200.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(img_test, img_new):\n",
    "    c = ConvNetFeatureSaver()\n",
    "    # Extract features_new\n",
    "    img_new = transforms.Resize(224)(img_new)\n",
    "    img_new = transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))(img_new)\n",
    "    features_new = c.extract(img_new)\n",
    "\n",
    "    # Extract features_real\n",
    "    img_test = transforms.Resize(224)(img_test)\n",
    "    img_test = transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))(img_test)\n",
    "    features_real = c.extract(img_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    score = np.zeros(2 * 3 + 2)\n",
    "    for i in range(0,2):\n",
    "        score[3*i:3*i+3] = compute_score(features_real[i],features_new[i],sqrt=True)\n",
    "    score[6] = inception_score(features_new[3])\n",
    "    score[7] = fid(features_real[3], features_new[3])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Small sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 200; nr_model = 7 ; nr_metric = 8\n",
    "score = np.zeros((10,nr_model,nr_metric))\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=2000, shuffle=True)\n",
    "img_test,attr = next(iter(dataloader_test))\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=4000, shuffle=True)\n",
    "img_train,attr = next(iter(dataloader_train))\n",
    "\n",
    "for n in range(200,2001,200):   \n",
    "    i = int(n/200-1)\n",
    "    \n",
    "    \n",
    "    # Get latent variable\n",
    "    with torch.no_grad():\n",
    "        lv = model_AE.encode(img_train)\n",
    "    lv = lv.detach().numpy()\n",
    " \n",
    "    # Test set\n",
    "    with torch.no_grad():\n",
    "        y_test = model_AE.encode(img_test)\n",
    "    \n",
    "    for m in [0,1,2,3,4,5,6,7]:\n",
    "        \n",
    "            # Beta Copula\n",
    "        if m == 0: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum = np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new = lv[randnum]\n",
    "                y_sample[num*n:(n)*(num+1),:] = sampleing1(lv_new, lv_new, lv_new.shape[0])\n",
    "            if 2000%n!=0:\n",
    "                randnum = np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new = lv[randnum]\n",
    "                y_sample[int(2000/n)*n:,:]=sampleing1(lv_new, lv_new, 2000%n)          \n",
    "                y_sample=torch.Tensor(y_sample)\n",
    "                \n",
    "           \n",
    "        # VAE\n",
    "        elif m == 1:\n",
    "            y_sample=torch.randn(2000, 20)\n",
    "           \n",
    "\n",
    "        # Vine copula trun_level=15\n",
    "        elif m == 2:\n",
    "            copula_controls = base.list(family_set=\"tll\", trunc_lvl=15, cores=1)\n",
    "            for num in range(0,int(2000/n)):\n",
    "                fixed_noise = np.random.rand(n, lv.shape[1]) \n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                vine_obj = rvinecop.vine(lv_new, copula_controls=copula_controls)\n",
    "                sampled_r = rvinecop.inverse_rosenblatt(fixed_noise, vine_obj)\n",
    "                y_sample[num*n:(n)*(num+1),:] =torch.Tensor( np.asarray(sampled_r)).view(n, -1).to(\"cpu\")\n",
    "            if 2000%n!=0:\n",
    "                fixed_noise = np.random.rand(2000%n, lv.shape[1]) \n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                vine_obj = rvinecop.vine(lv_new, copula_controls=copula_controls)\n",
    "                sampled_r = rvinecop.inverse_rosenblatt(fixed_noise, vine_obj)\n",
    "                y_sample[int(2000/n)*n:,:]=torch.Tensor(np.asarray(sampled_r)).view(2000%n, -1).to(\"cpu\")\n",
    "            del sampled_r  \n",
    "            y_sample=torch.Tensor(y_sample)\n",
    "                \n",
    "                \n",
    "        # Gauss  \n",
    "        elif m==3:\n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                mean = np.mean(lv_new, axis=0)\n",
    "                cov = np.cov(lv_new, rowvar=0)\n",
    "                y_sample[num*n:(n)*(num+1),:] = torch.tensor(np.random.multivariate_normal(mean, cov, lv_new.shape[0])).float()\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                mean = np.mean(lv_new, axis=0)\n",
    "                cov = np.cov(lv_new, rowvar=0)\n",
    "                y_sample[int(2000/n)*n:,:] = torch.tensor(np.random.multivariate_normal(mean, cov, 2000%n)).float()\n",
    "                    \n",
    "                \n",
    "        # Independent\n",
    "        if m == 4: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                y_sample[num*n:(n)*(num+1),:] = indep_sampling(lv_new, lv_new, lv_new.shape[0])\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                y_sample[int(2000/n)*n:,:]=indep_sampling(lv_new, lv_new, 2000%n)\n",
    "                    \n",
    "            y_sample=torch.tensor(shuffle_along_axis(y_sample, axis=0)).float()\n",
    "            \n",
    "            \n",
    "        # GMM\n",
    "        if m == 5: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                gm = GaussianMixture(n_components=10, random_state=0).fit(lv_new)\n",
    "                y_sample[num*n:(n)*(num+1),:] = torch.tensor(gm.sample(n_samples=lv_new.shape[0])[0]).float()\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                gm = GaussianMixture(n_components=10, random_state=0).fit(lv_new)\n",
    "                y_sample[int(2000/n)*n:,:] = torch.tensor(gm.sample(n_samples=2000%n)[0]).float()\n",
    "                    \n",
    "                    \n",
    "        # KDE\n",
    "        if m == 6: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                grid = GridSearchCV(KernelDensity(),\n",
    "                {'bandwidth': np.linspace(0.1, 2.0, 40)},\n",
    "                cv=10) \n",
    "                grid.fit(lv_new)\n",
    "                kde = grid.best_estimator_\n",
    "                lvnew_kde=kde.sample(n_samples=lv_new.shape[0])\n",
    "                lvnew_kde=np.array(lvnew_kde,dtype=np.double)\n",
    "                y_sample[num*n:(n)*(num+1),:] = torch.tensor(lvnew_kde).float()\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                grid = GridSearchCV(KernelDensity(),\n",
    "                {'bandwidth': np.linspace(0.1, 2.0, 40)},\n",
    "                cv=10) \n",
    "                grid.fit(lv_new)\n",
    "                kde = grid.best_estimator_\n",
    "                lvnew_kde=kde.sample(n_samples=2000%n)\n",
    "                lvnew_kde=np.array(lvnew_kde,dtype=np.double)\n",
    "                y_sample[int(2000/n)*n:,:] = torch.tensor(lvnew_kde).float()\n",
    "                    \n",
    "        # RealNVP        \n",
    "        elif m==7:\n",
    "            randnum=np.random.choice(4000,size=n,replace=False)#np.random.randint(0,2000,size=n)\n",
    "            lv_new=lv[randnum]\n",
    "            nnets = lambda: nn.Sequential(nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20),nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20), nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20),nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20),nn.Tanh())\n",
    "            nett = lambda: nn.Sequential(nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20),nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20),nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20),nn.Linear(20, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 20))\n",
    "            masks = torch.from_numpy(np.array([np.resize([1,0], [1,20]),np.resize([0,1], [1,20])]*3).astype(np.float32))\n",
    "            prior = distributions.MultivariateNormal(torch.zeros(20), torch.eye(20))\n",
    "            flow = RealNVP(nets, nett, masks, prior)\n",
    "            optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-4)\n",
    "            loss_hist = np.array([])\n",
    "            num_samples=128\n",
    "            for a in tqdm(range(2001)): \n",
    "                helper=np.random.randint(0,n-1,size=num_samples)\n",
    "                x_np= lv_new[helper]\n",
    "                x_np = x_np.astype(np.float32)\n",
    "                loss = -flow.log_prob(torch.from_numpy(x_np)).mean()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                    \n",
    "            x = flow.sample(2000).detach().numpy()\n",
    "            x=np.reshape(x,newshape=(x.shape[0],x.shape[2]))\n",
    "            y_sample=torch.tensor(x).float()\n",
    "            \n",
    "                    \n",
    "            \n",
    "        #Generate iamges by deoding\n",
    "        if m == 2: \n",
    "            img_new = model_VAE.decode(torch.tensor(y_sample).float())\n",
    "        else:\n",
    "            img_new = model_AE.decode(torch.tensor(y_sample).float())\n",
    "               \n",
    "        # Evaluate\n",
    "        with torch.no_grad():\n",
    "            s = calculate_score(img_test,img_new)\n",
    "            score[i,m,:] = s\n",
    "\n",
    "            print(s)\n",
    "            print('Finished_{}'.format(m))\n",
    "    \n",
    "    print(\"Finished:\",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "xaxis = [i for i in range(200,2001,200)]\n",
    "title = ['EMD PIXEL','MMD PIXEL','1NN PIXEL','EMD CONV','MMD CONV','1NN CONV','Inception','FID']\n",
    "label = ['EBCAE','VCAE_5','VAE','VCAE','Gauss','Independent','GMM','KDE']\n",
    "score_show = score[:19,:,[0,1,2,3,4,5,6,7]]\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "fig=plt.figure(figsize=(8.27, 3.8))\n",
    "k=1\n",
    "for i in [0,3,1,4,2,5,6,7]:\n",
    "    color = iter(cm.Set2(np.linspace(0, 1, 8)))\n",
    "    ax = plt.subplot(2,4,k)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    #ax.grid(visible=True, which='both', axis='both', alpha=0.2)\n",
    "    plt.xticks(xaxis[0::2])\n",
    "    for j in [0,2,3,4,5,6,7]:\n",
    "        if j==7:\n",
    "            c = next(color)\n",
    "        c = next(color)\n",
    "        ax.plot(xaxis,score_show[:,j,i],'--bo',label=label[j], color=c,markersize=3.5)\n",
    " \n",
    "        plt.xlabel('sample size',fontsize=10)\n",
    "    ax.set_title(title[i])\n",
    "    k+=1\n",
    "    #if i == 3: ax.legend()\n",
    "\n",
    "lines_labels = [axi.get_legend_handles_labels() for axi in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]    \n",
    "lines=[lines[0],lines[1],lines[2],lines[3],lines[4],lines[5],lines[6]]\n",
    "labels=[labels[0],labels[1],labels[2],labels[3],labels[4],labels[5],labels[6]]\n",
    "\n",
    "bbox_transform=fig.transFigure\n",
    "fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05),fancybox=False, markerscale=2\n",
    "          ,shadow=False, framealpha=0, ncol=7, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"score_SVHN_samplesize.png\",dpi=300,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
