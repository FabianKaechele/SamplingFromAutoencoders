{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation over Sample Size on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA,MNIST\n",
    "import torchvision.datasets as dset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "\n",
    "import timeit\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "    \n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "robjects.numpy2ri.activate()\n",
    "base = importr('base')\n",
    "#utils = importr('utils')\n",
    "#utils.install_packages('rvinecopulib')\n",
    "#utils.install_packages('Rcpp')\n",
    "rvinecop = importr('rvinecopulib')\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from AE import *\n",
    "from Sampling import *\n",
    "from Metric import *\n",
    "from RealNVP import *\n",
    "\n",
    "trans0 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "path = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset_train = MNIST(path,train=True, transform=trans0, download=True)\n",
    "dataset_test = MNIST(path,train=False, transform=trans0, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "model_AE = AE_MNIST(image_size=32, channel_num=1,kernel_num=128, z_size=10)\n",
    "model_AE.load_state_dict(torch.load('./ae_MNIST_200.pth',map_location=torch.device('cpu')))\n",
    "model_VAE = VAE_MNIST(image_size=32, channel_num=1, kernel_num=128, z_size=10)\n",
    "model_VAE.load_state_dict(torch.load('./vae_MNIST_200.pth'\n",
    "                                          ,map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 200; nr_model = 8 ; nr_metric = 6\n",
    "score = np.zeros((10,nr_model,nr_metric)); time = np.zeros((10,nr_model))\n",
    "\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=2000, shuffle=True)\n",
    "img_test,attr = next(iter(dataloader_test))\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=4000, shuffle=True)\n",
    "img_train,attr = next(iter(dataloader_train))\n",
    "\n",
    "for n in range(200,2001,200):   \n",
    "    i = int(n/200-1) \n",
    "    \n",
    "    # Get latent variable\n",
    "    with torch.no_grad():\n",
    "        lv = model_AE.encode(img_train)\n",
    "    lv = lv.detach().numpy()\n",
    "\n",
    "\n",
    "    # Test set\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            y_test = model_AE.encode(img_test)\n",
    "    \n",
    "    for m in [0,1,2,3,4,5,6,7]:\n",
    "        s0 = timeit.default_timer()\n",
    "        y_sample=np.zeros((2000,lv.shape[1]))\n",
    "        \n",
    "            \n",
    "        # Beta Copula\n",
    "        if m == 0: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                y_sample[num*n:(n)*(num+1),:] = sampleing1(lv_new, lv_new, lv_new.shape[0])\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                y_sample[int(2000/n)*n:,:]=sampleing1(lv_new, lv_new, 2000%n)\n",
    "                    \n",
    "            y_sample=torch.Tensor(y_sample)\n",
    "                \n",
    "          \n",
    "        # VAE\n",
    "        elif m == 1:            \n",
    "            y_sample=torch.randn(2000, 10)\n",
    "           \n",
    "\n",
    "        # Vine copula trun_level=15\n",
    "        elif m == 2:\n",
    "            copula_controls = base.list(family_set=\"tll\", trunc_lvl=15, cores=1)\n",
    "            for num in range(0,int(2000/n)):\n",
    "                fixed_noise = np.random.rand(n, lv.shape[1]) \n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                vine_obj = rvinecop.vine(lv_new, copula_controls=copula_controls)\n",
    "                sampled_r = rvinecop.inverse_rosenblatt(fixed_noise, vine_obj)\n",
    "                y_sample[num*n:(n)*(num+1),:] =torch.Tensor( np.asarray(sampled_r)).view(n, -1).to(\"cpu\")\n",
    "            if 2000%n!=0:\n",
    "                fixed_noise = np.random.rand(2000%n, lv.shape[1]) \n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                vine_obj = rvinecop.vine(lv_new, copula_controls=copula_controls)\n",
    "                sampled_r = rvinecop.inverse_rosenblatt(fixed_noise, vine_obj)\n",
    "                y_sample[int(2000/n)*n:,:]=torch.Tensor(np.asarray(sampled_r)).view(2000%n, -1).to(\"cpu\")\n",
    "            del sampled_r  \n",
    "            y_sample=torch.Tensor(y_sample)\n",
    "                \n",
    "                \n",
    "        # Gauss  \n",
    "        elif m==3:\n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                mean = np.mean(lv_new, axis=0)\n",
    "                cov = np.cov(lv_new, rowvar=0)\n",
    "                y_sample[num*n:(n)*(num+1),:] = torch.tensor(np.random.multivariate_normal(mean, cov, lv_new.shape[0])).float()\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                mean = np.mean(lv_new, axis=0)\n",
    "                cov = np.cov(lv_new, rowvar=0)\n",
    "                y_sample[int(2000/n)*n:,:] = torch.tensor(np.random.multivariate_normal(mean, cov, 2000%n)).float()\n",
    "            y_sample=torch.tensor(y_sample).float()\n",
    "                    \n",
    "                \n",
    "        # Independent\n",
    "        if m == 4: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                y_sample[num*n:(n)*(num+1),:] = indep_sampling(lv_new, lv_new, lv_new.shape[0])\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                y_sample[int(2000/n)*n:,:]=indep_sampling(lv_new, lv_new, 2000%n)\n",
    "                    \n",
    "            y_sample=torch.tensor(shuffle_along_axis(y_sample, axis=0)).float()\n",
    "                \n",
    "            \n",
    "        # GMM\n",
    "        if m == 5: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                gm = GaussianMixture(n_components=10, random_state=0).fit(lv_new)\n",
    "                y_sample[num*n:(n)*(num+1),:] = torch.tensor(gm.sample(n_samples=lv_new.shape[0])[0]).float()\n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                gm = GaussianMixture(n_components=10, random_state=0).fit(lv_new)\n",
    "                y_sample[int(2000/n)*n:,:] = torch.tensor(gm.sample(n_samples=2000%n)[0]).float()\n",
    "                y_sample=torch.tensor(y_sample).float()    \n",
    "                \n",
    "                \n",
    "        # KDE\n",
    "        if m == 6: \n",
    "            for num in range(0,int(2000/n)):\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                grid = GridSearchCV(KernelDensity(),\n",
    "                {'bandwidth': np.linspace(0.1, 2.0, 40)},\n",
    "                cv=10) \n",
    "                grid.fit(lv_new)\n",
    "                kde = grid.best_estimator_\n",
    "                lvnew_kde=kde.sample(n_samples=lv_new.shape[0])\n",
    "                lvnew_kde=np.array(lvnew_kde,dtype=np.double)           \n",
    "                y_sample[num*n:(n)*(num+1),:] = torch.tensor(lvnew_kde).float()\n",
    "                \n",
    "            if 2000%n!=0:\n",
    "                randnum=np.random.choice(4000,size=n,replace=False)\n",
    "                lv_new=lv[randnum]\n",
    "                grid = GridSearchCV(KernelDensity(),\n",
    "                {'bandwidth': np.linspace(0.1, 2.0, 40)},\n",
    "                cv=10) \n",
    "                grid.fit(lv_new)\n",
    "                kde = grid.best_estimator_\n",
    "                lvnew_kde=kde.sample(n_samples=2000%n)\n",
    "                lvnew_kde=np.array(lvnew_kde,dtype=np.double)\n",
    "                y_sample[int(2000/n)*n:,:] = torch.tensor(lvnew_kde).float()\n",
    "                y_sample=torch.tensor(y_sample).float() \n",
    "                \n",
    "        # Real NVP\n",
    "        elif m==7:\n",
    "            randnum=np.random.choice(4000,size=n,replace=False)#np.random.randint(0,2000,size=n)\n",
    "            lv_new=lv[randnum]\n",
    "            masks = torch.from_numpy(np.array([[0, 1, 0, 1, 0, 1, 0, 1, 0, 1], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]] * 3).astype(np.float32))\n",
    "            nets = lambda: nn.Sequential(nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10), nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Tanh())\n",
    "            nett = lambda: nn.Sequential(nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10))\n",
    "            prior = distributions.MultivariateNormal(torch.zeros(10), torch.eye(10))\n",
    "            flow = RealNVP(nets, nett, masks, prior)\n",
    "            optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-4)\n",
    "            loss_hist = np.array([])\n",
    "            num_samples=128\n",
    "            for a in tqdm(range(2001)): \n",
    "                helper=np.random.randint(0,n-1,size=num_samples)\n",
    "                x_np= lv_new[helper]\n",
    "                x_np = x_np.astype(np.float32)\n",
    "                loss = -flow.log_prob(torch.from_numpy(x_np)).mean()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                    \n",
    "            x = flow.sample(2000).detach().numpy()\n",
    "            x=np.reshape(x,newshape=(x.shape[0],x.shape[2]))\n",
    "            y_sample=torch.tensor(x).float()\n",
    "            \n",
    "            \n",
    "            # Generate iamges by deoding\n",
    "        if m == 2: \n",
    "            img_new = model_VAE.decode(torch.tensor(y_sample).float())\n",
    "        else:\n",
    "            img_new = model_AE.decode(torch.tensor(y_sample).float())\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            sc1 = compute_score(img_test,img_new)\n",
    "            sc2 = compute_score(y_test,y_sample)\n",
    "            for j in range(3): score[i,m,j] = sc1[j]\n",
    "            for j in range(3,6): score[i,m,j] = sc2[j-3]\n",
    "            print('Finished_{}'.format(m))\n",
    "    \n",
    "    print(\"Finished:\",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "score1=score[:10,:,:]\n",
    "xaxis = [i for i in range(200,2001,200)]\n",
    "title = ['EMD PIXEL','MMD PIXEL','1NN PIXEL','EMD CONV','MMD CONV','1NN CONV']\n",
    "label =  ['EBCAE','VAE','VCAE_15','Gauss','Independent','GMM','KDE']\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "fig=plt.figure(figsize=(8.27, 3.8))\n",
    "k=1\n",
    "for i in [0,3,1,4,2,5]:\n",
    "    ax = plt.subplot(2,3,k)\n",
    "    color = iter(cm.Set2(np.linspace(0, 1, 8)))\n",
    "    plt.xticks(xaxis[0::2])\n",
    "    for j in [0,1,2,3,4,5,6,7]:\n",
    "        c = next(color)\n",
    "        plt.xticks(fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        ax.plot(xaxis,score1[:,j,i],'--bo',label=label[j], color=c,markersize=3.5)\n",
    "        plt.xlabel('epochs',fontsize=10)\n",
    "        \n",
    "        \n",
    "    ax.set_title(title[i])\n",
    "    k+=1\n",
    "    \n",
    "lines_labels = [axi.get_legend_handles_labels() for axi in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]   \n",
    "\n",
    "\n",
    "lines=[lines[0],lines[1],lines[2],lines[3],lines[4],lines[5],lines[6]]\n",
    "labels=[labels[0],labels[1],labels[2],labels[3],labels[4],labels[5],labels[6]]\n",
    "\n",
    "bbox_transform=fig.transFigure\n",
    "fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05),fancybox=False, markerscale=2\n",
    "           ,shadow=False, framealpha=0, ncol=7, fontsize=10)    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"score_MNIST_samplesize_VGL.png\",dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Small sample sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(dataset_test, batch_size=2000, shuffle=True)\n",
    "img_test,attr = next(iter(dataloader_test))\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=2000, shuffle=True)\n",
    "img_train,attr = next(iter(dataloader_train))\n",
    "for n in range(2000,2001,200):   \n",
    "\n",
    "    \n",
    "    # Get latent variable\n",
    "    s0 = timeit.default_timer()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        lv = model_AE.encode(img_train)\n",
    "    lv = lv.detach().numpy()\n",
    "\n",
    "    s1 = timeit.default_timer()\n",
    "    encoding_time = s1-s0\n",
    "    print('Encoding Time: ',encoding_time)\n",
    "\n",
    "    \n",
    "    for m in [0,1,2,3,4,5,6,7]:\n",
    "            print(m)\n",
    "            \n",
    "            # Beta Copula\n",
    "            if m == 0:     \n",
    "                y_sample,learning_time,sampling_time = sampling1_time(lv, lv, lv.shape[0])#, seed=500)        \n",
    "                y_sample=torch.Tensor(y_sample)\n",
    "                \n",
    "\n",
    "            # VAE\n",
    "            elif m == 1:\n",
    "                s0 = timeit.default_timer()\n",
    "                y_sample=torch.randn(2000, 100)\n",
    "                sampling_time= timeit.default_timer()-s0\n",
    "                learning_time=0\n",
    "           \n",
    "\n",
    "            # Vine copula trun_level=15\n",
    "            elif m == 2:\n",
    "                copula_controls = base.list(family_set=\"tll\", trunc_lvl=15, cores=1)\n",
    "                s0 = timeit.default_timer()\n",
    "                vine_obj = rvinecop.vine(lv, copula_controls=copula_controls)\n",
    "                learning_time= timeit.default_timer()-s0\n",
    "                \n",
    "                s0 = timeit.default_timer()\n",
    "                fixed_noise = np.random.rand(n, lv.shape[1])\n",
    "                sampled_r = rvinecop.inverse_rosenblatt(fixed_noise, vine_obj)\n",
    "                y_sample =torch.Tensor( np.asarray(sampled_r)).view(n, -1).to(\"cpu\")\n",
    "                y_sample=torch.Tensor(y_sample)\n",
    "                sampling_time= timeit.default_timer()-s0\n",
    "                \n",
    "                \n",
    "            # Gauss \n",
    "            elif m==3:\n",
    "                s0 = timeit.default_timer()\n",
    "                mean = np.mean(lv, axis=0)\n",
    "                cov = np.cov(lv, rowvar=0)\n",
    "                learning_time= timeit.default_timer()-s0\n",
    "                    \n",
    "                s0 = timeit.default_timer()\n",
    "                y_sample = torch.tensor(np.random.multivariate_normal(mean, cov, lv.shape[0])).float()\n",
    "                sampling_time= timeit.default_timer()-s0\n",
    "\n",
    "                \n",
    "            # Independent\n",
    "            elif m == 4:  \n",
    "                y_sample,learning_time,sampling_time = indep_time(lv, lv, lv.shape[0])#, seed=500)\n",
    "               \n",
    "                    \n",
    "            # GMM\n",
    "            elif m == 5: \n",
    "                s0 = timeit.default_timer()\n",
    "                gm = GaussianMixture(n_components=10, random_state=0).fit(lv)\n",
    "                learning_time= timeit.default_timer()-s0\n",
    "                \n",
    "                s0 = timeit.default_timer()\n",
    "                y_sample = torch.tensor(gm.sample(n_samples=lv.shape[0])[0]).float()\n",
    "                sampling_time= timeit.default_timer()-s0\n",
    "               \n",
    "                    \n",
    "            # KDE\n",
    "            elif m == 6: \n",
    "                s0 = timeit.default_timer()\n",
    "                grid = GridSearchCV(KernelDensity(),\n",
    "                {'bandwidth': np.linspace(0.1, 2.0, 40)},\n",
    "                cv=10) # 20-fold cross-validation\n",
    "                grid.fit(lv)\n",
    "                kde = grid.best_estimator_\n",
    "                learning_time= timeit.default_timer()-s0\n",
    "                \n",
    "                s0 = timeit.default_timer()\n",
    "                lvnew_kde=kde.sample(n_samples=lv.shape[0])\n",
    "                lvnew_kde=np.array(lvnew_kde,dtype=np.double)\n",
    "                y_sample = torch.tensor(lvnew_kde).float()\n",
    "                sampling_time= timeit.default_timer()-s0\n",
    "                \n",
    "            elif m==7:\n",
    "                s0 = timeit.default_timer()\n",
    "                masks = torch.from_numpy(np.array([[0, 1, 0, 1, 0, 1, 0, 1, 0, 1], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]] * 3).astype(np.float32))\n",
    "                nets = lambda: nn.Sequential(nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10), nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Tanh())\n",
    "                nett = lambda: nn.Sequential(nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10))\n",
    "                prior = distributions.MultivariateNormal(torch.zeros(10), torch.eye(10))\n",
    "                flow = RealNVP(nets, nett, masks, prior)\n",
    "                optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-4)\n",
    "                loss_hist = np.array([])\n",
    "                num_samples=128\n",
    "                for a in tqdm(range(2001)): \n",
    "                    helper=np.random.randint(0,2000,size=num_samples)\n",
    "                    x_np= lv[helper]\n",
    "                    x_np = x_np.astype(np.float32)\n",
    "                    loss = -flow.log_prob(torch.from_numpy(x_np)).mean()\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    optimizer.step()\n",
    "                learning_time= timeit.default_timer()-s0\n",
    "                \n",
    "                s0 = timeit.default_timer()\n",
    "                x = flow.sample(2000).detach().numpy()\n",
    "                x=np.reshape(x,newshape=(x.shape[0],x.shape[2]))\n",
    "                y_sample=torch.tensor(x).float()\n",
    "                sampling_time= timeit.default_timer()-s0\n",
    "              \n",
    "\n",
    "            print(m,': ',learning_time,sampling_time,learning_time+sampling_time)\n",
    "            print('Finished_{}'.format(m))\n",
    "    \n",
    "    print(\"Finished:\",n,timeit.default_timer()- s1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
