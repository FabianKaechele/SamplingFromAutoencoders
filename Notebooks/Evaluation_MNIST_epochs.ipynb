{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1488766a",
   "metadata": {},
   "source": [
    "## Evaluation of sampling methods over epochs of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ba26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CelebA,MNIST\n",
    "import torchvision.datasets as dset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "import timeit\n",
    "\n",
    "import rpy2.robjects.numpy2ri\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "robjects.numpy2ri.activate()\n",
    "base = importr('base')\n",
    "#utils = importr('utils')\n",
    "#utils.install_packages('rvinecopulib')\n",
    "#utils.install_packages('Rcpp')\n",
    "rvinecop = importr('rvinecopulib')\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from AE import *\n",
    "from Sampling import *\n",
    "from Metric import *\n",
    "from RealNVP import *\n",
    "\n",
    "\n",
    "\n",
    "trans0 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "path = %pwd\n",
    "dataset_train = MNIST(path,train=True, transform=trans0, download=True)\n",
    "dataset_test = MNIST(path,train=False, transform=trans0, download=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ec95f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AE = AE_MNIST(image_size=32, channel_num=1,kernel_num=128, z_size=10)\n",
    "model_VAE = VAE_MNIST(image_size=32, channel_num=1, kernel_num=128, z_size=10)\n",
    "\n",
    "score=np.zeros((10,8,6)) # Epochs, # Models, # Scores\n",
    "\n",
    "# Encoded data for latent space\n",
    "n=2000    \n",
    "dataloader_train = DataLoader(dataset_train, batch_size=n, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=n, shuffle=True)\n",
    "img_train,attr = next(iter(dataloader_train))\n",
    "img_test,attr = next(iter(dataloader_test))\n",
    "\n",
    "\n",
    "for epoch in range(20,201,20):\n",
    "    i = int(epoch/20-1)\n",
    "  \n",
    "    # Load model according to epoch\n",
    "    model_AE.load_state_dict(torch.load('./ae_MNIST_{}.pth'.format(epoch)\n",
    "                             ,map_location=torch.device('cpu')))\n",
    "\n",
    "    model_VAE.load_state_dict(torch.load('./vae_MNIST_{}.pth'.format(epoch)\n",
    "                                         ,map_location=torch.device('cpu')))\n",
    "  \n",
    "\n",
    "    # Test set\n",
    "    with torch.no_grad():\n",
    "         y_test = model_AE.encode(img_test)\n",
    "      \n",
    "    \n",
    "    # Get latent variable\n",
    "    s0 = timeit.default_timer()\n",
    "\n",
    "    lv = model_AE.encode(img_train)\n",
    "    lv = lv.detach().numpy()\n",
    "\n",
    "    s1 = timeit.default_timer()\n",
    "    t1 = s1-s0\n",
    "    \n",
    "  \n",
    " \n",
    "    # Create samples\n",
    "    for m in [0,1,2,3,4,5,6,7]:\n",
    "        \n",
    "        s0 = timeit.default_timer()\n",
    "            \n",
    "        # Beta Copula\n",
    "        if m == 0: \n",
    "            y_sample = sampleing1(lv, lv, lv.shape[0], seed=500)\n",
    "           \n",
    "            \n",
    "        # VAE\n",
    "        elif m == 1: \n",
    "            y_sample=torch.randn(lv.shape[0], 10)\n",
    "\n",
    "                \n",
    "        # Vine copula trun_level=15\n",
    "        elif m == 2:\n",
    "            fixed_noise = np.random.rand(lv.shape[0], lv.shape[1]) \n",
    "            copula_controls = base.list(family_set=\"tll\", trunc_lvl=15, cores=1)\n",
    "            vine_obj = rvinecop.vine(lv, copula_controls=copula_controls)\n",
    "            sampled_r = rvinecop.inverse_rosenblatt(fixed_noise, vine_obj)\n",
    "            y_sample = torch.Tensor(np.asarray(sampled_r)).view(lv.shape[0], -1).to(\"cpu\")    \n",
    "                \n",
    "                \n",
    "        # Gauss\n",
    "        elif m == 3: \n",
    "            mean = np.mean(lv, axis=0)\n",
    "            cov = np.cov(lv, rowvar=0)\n",
    "            y_sample=torch.tensor(np.random.multivariate_normal(mean, cov, lv.shape[0])).float()\n",
    "            \n",
    "                \n",
    "        # Independent\n",
    "        elif m == 4: \n",
    "            #Indep\n",
    "            lv_new_indep =indep_sampling(lv,lv, lv.shape[0], seed=500)\n",
    "            y_sample= lv_new_indep.detach().numpy()\n",
    "            y_sample=torch.tensor(shuffle_along_axis(lv_new_indep, axis=0)).float()\n",
    "\n",
    "                \n",
    "        # GMM\n",
    "        elif m == 5: \n",
    "            gm = GaussianMixture(n_components=10, random_state=0).fit(lv)\n",
    "            y_sample=torch.tensor(gm.sample(n_samples=lv.shape[0])[0]).float()\n",
    "                \n",
    "             \n",
    "        # KDE\n",
    "        elif m == 6: \n",
    "            grid = GridSearchCV(KernelDensity(),\n",
    "                {'bandwidth': np.linspace(0.1, 2.0, 40)},\n",
    "                cv=10) \n",
    "            grid.fit(lv)\n",
    "            kde = grid.best_estimator_\n",
    "  \n",
    "            lvnew_kde=kde.sample(n_samples=lv.shape[0])\n",
    "            lvnew_kde=np.array(lvnew_kde,dtype=np.double)\n",
    "            y_sample=torch.tensor(lvnew_kde).float()\n",
    "            \n",
    "         # Real NVP\n",
    "         elif m==7: \n",
    "            masks = torch.from_numpy(np.array([[0, 1, 0, 1, 0, 1, 0, 1, 0, 1], [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]] * 3).astype(np.float32))\n",
    "            nets = lambda: nn.Sequential(nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10), nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Tanh())\n",
    "            nett = lambda: nn.Sequential(nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10),nn.Linear(10, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 10))\n",
    "            prior = distributions.MultivariateNormal(torch.zeros(10), torch.eye(10))\n",
    "            flow = RealNVP(nets, nett, masks, prior)\n",
    "            optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-4)\n",
    "            loss_hist = np.array([])\n",
    "            num_samples=128\n",
    "            for a in tqdm(range(2001)): \n",
    "                helper=np.random.randint(0,2000,size=num_samples)\n",
    "                x_np= lv[helper]\n",
    "                x_np = x_np.astype(np.float32)\n",
    "                loss = -flow.log_prob(torch.from_numpy(x_np)).mean()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                   \n",
    "            x = flow.sample(2000).detach().numpy()\n",
    "            x=np.reshape(x,newshape=(x.shape[0],x.shape[2]))\n",
    "            y_sample=torch.tensor(x).float()\n",
    "                \n",
    "            \n",
    "            \n",
    "        # Decode    \n",
    "        if m == 2: \n",
    "            img_new = model_VAE.decode(torch.tensor(y_sample).float())\n",
    "        else:\n",
    "            img_new = model_AE.decode(torch.tensor(y_sample).float())\n",
    "                \n",
    "        # Compute score    \n",
    "        with torch.no_grad():   \n",
    "            sc1 = compute_score(img_test,img_new)\n",
    "            sc2 = compute_score(y_test,y_sample)\n",
    "\n",
    "            for j in range(3): score[i,m,j] = sc1[j]\n",
    "            for j in range(3,6): score[i,m,j] = sc2[j-3]\n",
    "                \n",
    "    print(\"Finished:\",epoch,timeit.default_timer()- s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ada9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(score,'./score_MNIST_epoch_all_VGL.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882361f",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62043173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "score1=score[:10,:,:]\n",
    "xaxis = [i for i in range(20,201,20)]\n",
    "title = ['EMD PIXEL','MMD PIXEL','1NN PIXEL','EMD CONV','MMD CONV','1NN CONV']\n",
    "label =  ['EBCAE','VCAE_5','VAE','VCAE_15','Gauss','Independent','GMM','KDE','RealNVP']\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "fig=plt.figure(figsize=(8.27, 3.8))\n",
    "k=1\n",
    "for i in [0,3,1,4,2,5]:\n",
    "    ax = plt.subplot(2,3,k)\n",
    "    color = iter(cm.Set2(np.linspace(0, 1, 8)))\n",
    "    plt.xticks(xaxis[0::2])\n",
    "    for j in [0,2,3,4,5,6,7]:\n",
    "        c = next(color)\n",
    "        plt.xticks(fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        ax.plot(xaxis,score1[:,j,i],'--bo',label=label[j], color=c,markersize=3.5)\n",
    "        plt.xlabel('epochs',fontsize=10)\n",
    "        \n",
    "        \n",
    "    ax.set_title(title[i])\n",
    "    k+=1\n",
    "    \n",
    "lines_labels = [axi.get_legend_handles_labels() for axi in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]   \n",
    "\n",
    "\n",
    "lines=[lines[0],lines[1],lines[2],lines[3],lines[4],lines[5],lines[6],lines[7]]\n",
    "labels=[labels[0],labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7]]\n",
    "\n",
    "bbox_transform=fig.transFigure\n",
    "fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05),fancybox=False, markerscale=2\n",
    "           ,shadow=False, framealpha=0, ncol=7, fontsize=10)    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"score_MNIST_epoch_VGL.png\",dpi=300,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
